{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY8nsFOtJx0f2lI47aTCGR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenducminh2206/NLP-Projects/blob/main/Text_Classification_CMC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pyarrow"
      ],
      "metadata": {
        "id": "v6n2pCDgVBJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "3IudUWmcUHzR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "hrtaxhuHVz7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "75nMbwV6cx9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import DataCollatorWithPadding"
      ],
      "metadata": {
        "id": "hngxKwjRT40Q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "ibX2XhYlboqx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "_hu0OUAAdGti"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_path):\n",
        "  df = pd.read_json(data_path)\n",
        "  label2idx = {label: idx for idx, label in enumerate(df['label'].unique())}\n",
        "  idx2label = {idx: label for idx, label in label2idx.items()}\n",
        "\n",
        "  # Prepare data\n",
        "  df['label'] = df['label'].map(label2idx)\n",
        "\n",
        "  # Split the data into training and validation sets\n",
        "  train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "  # Initialize tokenizer and model\n",
        "  tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "  # Tokenization\n",
        "  def tokenize(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "  train_dataset = Dataset.from_pandas(train_df)\n",
        "  val_dataset = Dataset.from_pandas(val_df)\n",
        "  train_dataset = train_dataset.map(tokenize, batched=True)\n",
        "  val_dataset = val_dataset.map(tokenize, batched=True)\n",
        "\n",
        "  # Set dataset format for Pytorch\n",
        "  train_dataset.set_format(type=\"torch\", columns=['input_ids', 'attention_mask', 'label'])\n",
        "  val_dataset.set_format(type=\"torch\", columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "  # Initialize the model\n",
        "  model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=len(label2idx))\n",
        "  model.config.id2label = idx2label\n",
        "  model.config.label2id = label2idx\n",
        "\n",
        "  # Data collator\n",
        "  data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "  # Training arguments\n",
        "  training_args = TrainingArguments(\n",
        "      output_dir='./results',\n",
        "      evaluation_strategy=\"epoch\",\n",
        "      learning_rate=2e-5,\n",
        "      per_device_train_batch_size=16,\n",
        "      per_device_eval_batch_size=16,\n",
        "      num_train_epochs=3,\n",
        "      weight_decay=0.01,\n",
        "      logging_dir='./logs',\n",
        "      save_strategy=\"epoch\"\n",
        "  )\n",
        "\n",
        "  # Trainer\n",
        "  trainer = Trainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=train_dataset,\n",
        "      eval_dataset=val_dataset,\n",
        "      data_collator=data_collator\n",
        "  )\n",
        "\n",
        "  # Train the model\n",
        "  trainer.train()\n",
        "\n",
        "  # Save the trained model\n",
        "  trainer.save_model('./trained_model_xlmroberta')\n"
      ],
      "metadata": {
        "id": "StavJCfVWeXD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train('/content/final_data_category.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "WmtoJGspbWFN",
        "outputId": "363e6e60-e886-4077-bb85-5de0bd4483d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='26' max='984' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 26/984 10:59 < 7:18:32, 0.04 it/s, Epoch 0.08/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}